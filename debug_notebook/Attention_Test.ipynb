{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from data_loader import build_vocab, get_loader\n",
    "from model import EncoderCNN, DecoderRNN \n",
    "from attn_model import AttnEncoder\n",
    "from model import ResNet, ResidualBlock\n",
    "import torch\n",
    "from torch.autograd import Variable \n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "import torch.nn as nn \n",
    "from Attention import Attn\n",
    "\n",
    "h_dec = torch.rand(128,26)\n",
    "\n",
    "def to_var(x, volatile=False):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda(1)\n",
    "    return Variable(x, volatile=volatile)\n",
    "\n",
    "def rearrange_tensor(x, batch_size, caption_size):\n",
    "    for i in range(caption_size):\n",
    "        temp = x[i*batch_size:(i+1)*batch_size].view(batch_size, -1)\n",
    "        if i == 0:\n",
    "            temp_cat = temp \n",
    "        else: \n",
    "            temp_cat = torch.cat((temp_cat,  temp), 1)\n",
    "\n",
    "    return temp_cat\n",
    "\n",
    "root_path ='data/circle_and_rect/'\n",
    "vocab_path ='data/vocab.pkl'\n",
    "batch_size= 64\n",
    "num_workers = 2 \n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers =1 \n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Load vocabulary wrapper\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "len_vocab = vocab.idx\n",
    "\n",
    "data_loader = get_loader(root_path, vocab, \n",
    "                         transform, batch_size,\n",
    "                         shuffle=True, num_workers=num_workers) \n",
    "\n",
    "encoder = ResNet(ResidualBlock, [3, 3, 3],len_vocab)\n",
    "decoder = DecoderRNN(len_vocab, len_vocab, \n",
    "                     len(vocab), num_layers)\n",
    "\n",
    "attn_encoder = AttnEncoder(ResidualBlock, [3,3,3])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    attn_encoder.cuda(1)\n",
    "    encoder.cuda(1)\n",
    "    decoder.cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len_vocab, 256).cuda(1)\n",
    "\n",
    "for i, (images, captions, lengths) in enumerate(data_loader):\n",
    "    if i > 1 : \n",
    "        break;\n",
    "    cap_ = torch.unsqueeze(captions,2)\n",
    "    one_hot_ = torch.FloatTensor(batch_size,captions.size(1),len_vocab).zero_()\n",
    "    one_hot_caption = one_hot_.scatter_(2, cap_, 1)    \n",
    "    leng = lengths\n",
    "    \n",
    "    images = to_var(images)  \n",
    "    captions2 = to_var(captions)\n",
    "    embed= embedding(captions2)\n",
    "    captions_ = to_var(one_hot_caption)\n",
    "    features = attn_encoder(images)\n",
    "    #outputs = decoder(features, captions_, lengt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5076  1.0960  0.0000  ...   0.0000  0.0000  0.0976\n",
       " 0.2090  0.4434  0.5210  ...   0.3823  0.3628  0.7257\n",
       " 0.7278  0.5846  1.3169  ...   0.2342  0.4350  1.7801\n",
       "          ...             ⋱             ...          \n",
       " 1.0747  0.0385  0.0000  ...   0.6958  0.5573  0.0000\n",
       " 0.0815  0.0000  0.0000  ...   0.1402  0.9188  0.2954\n",
       " 0.1069  0.2299  0.1398  ...   0.1414  0.2787  0.0000\n",
       "[torch.cuda.FloatTensor of size 128x256 (GPU 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_t= features.transpose(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5076  1.0960  0.0000  ...   0.0000  0.0000  0.0976\n",
       " 0.2090  0.4434  0.5210  ...   0.3823  0.3628  0.7257\n",
       " 0.7278  0.5846  1.3169  ...   0.2342  0.4350  1.7801\n",
       "          ...             ⋱             ...          \n",
       " 1.0747  0.0385  0.0000  ...   0.6958  0.5573  0.0000\n",
       " 0.0815  0.0000  0.0000  ...   0.1402  0.9188  0.2954\n",
       " 0.1069  0.2299  0.1398  ...   0.1414  0.2787  0.0000\n",
       "[torch.cuda.FloatTensor of size 128x256 (GPU 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_t.transpose(2,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_size =256\n",
    "init_layer = nn.Linear(feature_size, hidden_size).cuda(1)\n",
    "attn = Attn('general', feature_size, hidden_size).cuda(1)\n",
    "def init_lstm(features):\n",
    "\n",
    "    sums = torch.sum(features, 1)\n",
    "    out = torch.mul(sums, 1/features.size(1))\n",
    "    out = out.squeeze(1).unsqueeze(0) # 1, batch, feature_size\n",
    "    out = init_layer(out.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "    return out, out \n",
    "h_, c_ = init_lstm(features)\n",
    "context = attn(h_,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = torch.rand(2,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed = embedding(captions2)\n",
    "lstm_input = torch.cat((context, embed[:,1].unsqueeze(1)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(256, hidden_size, num_layers, batch_first=True).cuda(1)\n",
    "lstm_out, (h,c)  = lstm(lstm_input,(h_,c_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hiddens, states = lstm(lstm_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.1240  0.9178  1.0267  ...   0.4510  0.0968  0.6079\n",
       " 0.0058  0.0327  0.0026  ...   0.0016  0.1136  0.0467\n",
       " 0.0670  0.0000  0.0000  ...   0.0000  0.0017  0.0026\n",
       "          ...             ⋱             ...          \n",
       " 0.1510  0.3688  0.4252  ...   0.1172  0.3290  0.0373\n",
       " 0.0000  0.2017  0.1676  ...   0.2163  0.3762  0.0000\n",
       " 0.4142  0.3087  0.5983  ...   0.2978  0.1381  0.1541\n",
       "[torch.cuda.FloatTensor of size 128x256 (GPU 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.1240  0.0058  0.0670  ...   0.1510  0.0000  0.4142\n",
       " 0.9178  0.0327  0.0000  ...   0.3688  0.2017  0.3087\n",
       " 1.0267  0.0026  0.0000  ...   0.4252  0.1676  0.5983\n",
       "          ...             ⋱             ...          \n",
       " 0.4510  0.0016  0.0000  ...   0.1172  0.2163  0.2978\n",
       " 0.0968  0.1136  0.0017  ...   0.3290  0.3762  0.1381\n",
       " 0.6079  0.0467  0.0026  ...   0.0373  0.0000  0.1541\n",
       "[torch.cuda.FloatTensor of size 256x128 (GPU 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.transpose(2,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hiddens_temp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_int = Variable(torch.LongTensor([1])).cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding(x_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = torch.rand(2,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp.view(-1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed[:,1].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(256, hidden_size, num_layers, batch_first=True).cuda(1)\n",
    "temp_cat = torch.cat((features,embed),1)\n",
    "hiddens_temp, (h,c) = lstm(temp_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sums = torch.sum(features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = torch.mul(sums, 1/128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "h_=(h.squeeze(0))\n",
    "align_linear = nn.Linear(512, 256).cuda(1)\n",
    "de_h = align_linear(h_).unsqueeze(2)\n",
    "attn_weight = torch.bmm(features, de_h)\n",
    "attn_weight = F.softmax(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context = torch.bmm(attn_weight.transpose(2,1),features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 256])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = context.squeeze(1) + embed[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_input = torch.cat((context, embed[:,1].unsqueeze(1)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out, (h,c) = lstm(lstm_input, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_layer = nn.Linear(512,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = torch.rand(64,1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_ = h.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "align_linear = nn.Linear(512, 256).cuda(1)\n",
    "de_h = align_linear(h_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "de_hidden = de_h.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attn= torch.bmm(features, de_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attn.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "attn = F.softmax(attn.squeeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.transpose(1,2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.dot(h.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(len_vocab, hidden_size, num_layers, batch_first=True).cuda()\n",
    "packed  = pack_padded_sequence(captions_, leng, batch_first=True)\n",
    "lstm_out, _ = lstm(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_out"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
